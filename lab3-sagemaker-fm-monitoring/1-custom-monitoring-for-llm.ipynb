{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3a6a23",
   "metadata": {},
   "source": [
    "## Build a custom monitoring for foundation models with Amazon SageMaker Model Monitor\n",
    "\n",
    "This notebook shows how to:\n",
    "\n",
    "* Test custom monitoring script locally\n",
    "* Build a Docker container to include your custom drift algorithms\n",
    "* Monitor a live llama2 model endpoint for answer relevance\n",
    "\n",
    "\n",
    "Amazon SageMaker enables you to capture the input, output and metadata for invocations of the models that you deploy. It also enables you to bring your own metrics to analyze the data and monitor its quality. In this notebook, you learn how Amazon SageMaker enables these capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae63d2ee",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "To get started, make sure you have these prerequisites completed.\n",
    "\n",
    "* Complete the previous lab where you hosted a fine tuned Llama 2 model and enabled data capture on the live endpoint.\n",
    "* Add **Amazon Bedrock permission** to SageMaker Execution Role\n",
    "\n",
    "**inline policy**\n",
    "```\n",
    "{\n",
    "\t\"Version\": \"2012-10-17\",\n",
    "\t\"Statement\": [\n",
    "\t\t{\n",
    "\t\t\t\"Sid\": \"BedrockConsole\",\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Action\": [\n",
    "\t\t\t\t\"bedrock:*\"\n",
    "\t\t\t],\n",
    "\t\t\t\"Resource\": \"*\"\n",
    "\t\t}\n",
    "\t]\n",
    "}\n",
    "```\n",
    "**trusted relationship**\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": [\n",
    "                    \"sagemaker.amazonaws.com\",\n",
    "                    \"bedrock.amazonaws.com\"\n",
    "                ]\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "* Add permission to access ECR: Add **AmazonEC2ContainerRegistryFullAccess** policy to SageMaker Execution Role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5119e6c",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d484578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::376678947624:role/vegetation-management-works-SageMakerExecutionRole-OZ2K30BYST0I\n"
     ]
    }
   ],
   "source": [
    "# Handful of configuration\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "from sagemaker import get_execution_role, session\n",
    "\n",
    "region= boto3.Session().region_name\n",
    "a\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca7220",
   "metadata": {},
   "source": [
    "Bring the parameters from previous lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57243a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r endpoint_name\n",
    "%store -r default_bucket\n",
    "%store -r current_endpoint_capture_prefix\n",
    "%store -r s3_key_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e75a23",
   "metadata": {},
   "source": [
    "Download example captured data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1cdfb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-376678947624/Mikael110-llama-2-7b-guanaco-fp16/datacapture/llama-2-7b-2023-10-21-02-26-02-152-endpoint/AllTraffic/2023/10/21/02/35-09-353-1f41490f-4e1e-4c43-8d9a-2bb25433a0e6.jsonl to workspace/data/AllTraffic/2023/10/21/02/35-09-353-1f41490f-4e1e-4c43-8d9a-2bb25433a0e6.jsonl\n",
      "download: s3://sagemaker-us-west-2-376678947624/Mikael110-llama-2-7b-guanaco-fp16/datacapture/llama-2-7b-2023-10-21-02-26-02-152-endpoint/AllTraffic/2023/10/21/03/39-07-208-5459146d-0729-4374-b559-5b391308ce08.jsonl to workspace/data/AllTraffic/2023/10/21/03/39-07-208-5459146d-0729-4374-b559-5b391308ce08.jsonl\n",
      "download: s3://sagemaker-us-west-2-376678947624/Mikael110-llama-2-7b-guanaco-fp16/datacapture/llama-2-7b-2023-10-21-02-26-02-152-endpoint/AllTraffic/2023/10/21/03/41-03-334-9a247cda-7335-4bb7-b896-05f56d5b1afd.jsonl to workspace/data/AllTraffic/2023/10/21/03/41-03-334-9a247cda-7335-4bb7-b896-05f56d5b1afd.jsonl\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync s3://{default_bucket}/{current_endpoint_capture_prefix} workspace/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0e3ef",
   "metadata": {},
   "source": [
    "## Test script locally\n",
    "\n",
    "Preview the custom algorithm script to evaluate answer relevance.\n",
    "\n",
    "Explain how the algrorithm works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76f63157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpathlib\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mre\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mbase64\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mlangchain\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mllms\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Bedrock\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mlangchain\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36membeddings\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BedrockEmbeddings\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mlangchain\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mchains\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LLMChain\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mlangchain\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mprompts\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m PromptTemplate\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mlangchain\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mllms\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m enforce_stop_tokens\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "RELEVANCE_TEMPLATE = \u001b[33m\"\"\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mHuman: Generate question for the given answer.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mAssistant:Okay, give me an answer, and I will generate a question.\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m\\n\u001b[39;49;00m\u001b[33mHuman:Answer:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mThe PSLV-C56 mission is scheduled to be launched on Sunday, 30 July 2023 at 06:30 IST / 01:00 UTC. It will be launched from the Satish Dhawan Space Centre, Sriharikota, Andhra Pradesh, India \u001b[39;49;00m\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m\\n\u001b[39;49;00m\u001b[33mAssistant:Question:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mWhen is the scheduled launch date and time for the PSLV-C56 mission, and where will it be launched from?\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m\\n\u001b[39;49;00m\u001b[33mHuman:Answer:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m{answer}\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m\\n\u001b[39;49;00m\u001b[33mAssistant:Question:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m \u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "EVALUATOR = PromptTemplate(template=RELEVANCE_TEMPLATE, input_variables=[\u001b[33m\"\u001b[39;49;00m\u001b[33manswer\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# claculate how similar is the original question vs LLM generated questions\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# using cosine similarity\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcalculate_similarity\u001b[39;49;00m(question, generated_questions, embeddings):\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "    question_vec = np.asarray(embeddings.embed_query(question)).reshape(\u001b[34m1\u001b[39;49;00m, -\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    gen_question_vec = np.asarray(\u001b[37m\u001b[39;49;00m\r\n",
      "        embeddings.embed_documents(generated_questions)\u001b[37m\u001b[39;49;00m\r\n",
      "    )\u001b[37m\u001b[39;49;00m\r\n",
      "    norm = np.linalg.norm(gen_question_vec, axis=\u001b[34m1\u001b[39;49;00m) * np.linalg.norm(\u001b[37m\u001b[39;49;00m\r\n",
      "        question_vec, axis=\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    )\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m (\u001b[37m\u001b[39;49;00m\r\n",
      "        np.dot(gen_question_vec, question_vec.T).reshape(\u001b[37m\u001b[39;49;00m\r\n",
      "            -\u001b[34m1\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "        )\u001b[37m\u001b[39;49;00m\r\n",
      "        / norm\u001b[37m\u001b[39;49;00m\r\n",
      "    )\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mbase64_to_string\u001b[39;49;00m(base64_string):\u001b[37m\u001b[39;49;00m\r\n",
      "    base64_bytes = base64_string.encode(\u001b[33m'\u001b[39;49;00m\u001b[33mascii\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    string_bytes = base64.b64decode(base64_bytes) \u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m string_bytes.decode(\u001b[33m'\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mextract_instructions\u001b[39;49;00m(text):\u001b[37m\u001b[39;49;00m\r\n",
      "    pattern = \u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m### Instruction\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33mn(.*?)\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33mn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    match = re.search(pattern, text)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m match.group(\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mextract_answers\u001b[39;49;00m(text):\u001b[37m\u001b[39;49;00m\r\n",
      "    pattern = \u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m### Answer\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33mn\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33mn(.*)|### Answer\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33mn(.*)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    match = re.search(pattern, text)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m match.group(\u001b[34m1\u001b[39;49;00m) \u001b[35mor\u001b[39;49;00m match.group(\u001b[34m2\u001b[39;49;00m)   \u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mextract_contexts\u001b[39;49;00m(text):\u001b[37m\u001b[39;49;00m\r\n",
      "    pattern = \u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m### Context\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33mn(.*?)\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33mn\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33mn### Answer\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    match = re.search(pattern, text, re.DOTALL)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m match \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m match.group(\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# Helper function to extract question and answer from dataset\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mextract_qac\u001b[39;49;00m(input_data, output_data):\u001b[37m\u001b[39;49;00m\r\n",
      "    question = extract_instructions(json.loads(input_data)[\u001b[33m\"\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    context = extract_contexts(json.loads(input_data)[\u001b[33m\"\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "    generated_text = json.loads(base64_to_string(output_data))[\u001b[33m\"\u001b[39;49;00m\u001b[33moutputs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m][\u001b[33m\"\u001b[39;49;00m\u001b[33mgenerated_text\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\r\n",
      "    answer = extract_answers(generated_text)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m question, answer, context\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():    \u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Load dataset\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    questions, answers = [], []\u001b[37m\u001b[39;49;00m\r\n",
      "    infer_dir = os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mdataset_source\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "    jsonl_files = pathlib.Path(infer_dir).rglob(\u001b[33m'\u001b[39;49;00m\u001b[33m*.jsonl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m jsonl_files:\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mNo *.jsonl files found.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[37m\u001b[39;49;00m\r\n",
      "        exit()\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mfor\u001b[39;49;00m filepath \u001b[35min\u001b[39;49;00m jsonl_files:\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(filepath.absolute(), \u001b[33m'\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\r\n",
      "            \u001b[34mfor\u001b[39;49;00m line \u001b[35min\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\r\n",
      "                jsonl = json.loads(line)\u001b[37m\u001b[39;49;00m\r\n",
      "                input_data = jsonl[\u001b[33m'\u001b[39;49;00m\u001b[33mcaptureData\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mendpointInput\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\r\n",
      "                output_data = jsonl[\u001b[33m'\u001b[39;49;00m\u001b[33mcaptureData\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mendpointOutput\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\r\n",
      "                \u001b[37m\u001b[39;49;00m\r\n",
      "                q, a, c = extract_qac(input_data, output_data)\u001b[37m\u001b[39;49;00m\r\n",
      "                questions.append(q)\u001b[37m\u001b[39;49;00m\r\n",
      "                answers.append(a)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(questions)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(answers)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Initialize LLMs            \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    llm = Bedrock(\u001b[37m\u001b[39;49;00m\r\n",
      "        model_id=\u001b[33m\"\u001b[39;49;00m\u001b[33manthropic.claude-v2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "        model_kwargs={\u001b[33m\"\u001b[39;49;00m\u001b[33mmax_tokens_to_sample\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m200\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mtemperature\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m0\u001b[39;49;00m},\u001b[37m\u001b[39;49;00m\r\n",
      "        client=boto3.client(\u001b[33m\"\u001b[39;49;00m\u001b[33mbedrock-runtime\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, region_name=\u001b[33m'\u001b[39;49;00m\u001b[33mus-west-2\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\r\n",
      "    )\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "    llm_chain = LLMChain(llm=llm, prompt=EVALUATOR)\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[37m\u001b[39;49;00m\r\n",
      "    embeddings= BedrockEmbeddings(\u001b[37m\u001b[39;49;00m\r\n",
      "        client=boto3.client(\u001b[33m\"\u001b[39;49;00m\u001b[33mbedrock-runtime\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, region_name=\u001b[33m'\u001b[39;49;00m\u001b[33mus-west-2\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\r\n",
      "    )\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    scores = []\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mfor\u001b[39;49;00m q, a \u001b[35min\u001b[39;49;00m \u001b[36mzip\u001b[39;49;00m(questions, answers):\u001b[37m\u001b[39;49;00m\r\n",
      "        results = []\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m5\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\r\n",
      "            results.append(llm_chain.run(answer=a).strip())\u001b[37m\u001b[39;49;00m\r\n",
      "        cosine_sim = calculate_similarity(q, results, embeddings)\u001b[37m\u001b[39;49;00m\r\n",
      "        scores.append(cosine_sim.mean())\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33maverage relevancy score: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(scores)*\u001b[34m100\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m /100\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    output = {\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mllm_metrics\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: {\u001b[37m\u001b[39;49;00m\r\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33manswer_relevancy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: {\u001b[33m\"\u001b[39;49;00m\u001b[33mvalue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: np.mean(scores), \u001b[33m\"\u001b[39;49;00m\u001b[33mstandard_deviation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: np.std(scores)},\u001b[37m\u001b[39;49;00m\r\n",
      "        },\u001b[37m\u001b[39;49;00m\r\n",
      "    }\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mos.environ[\u001b[33m'\u001b[39;49;00m\u001b[33moutput_path\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[33m}\u001b[39;49;00m\u001b[33m/results.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\r\n",
      "        json.dump(output, f)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m\u001b[39;49;00m\r\n",
      "    main()\u001b[37m\u001b[39;49;00m\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize workspace/src/llm_monitoring.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14ee727d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tell me a fun fact about Boca Raton, Florida', 'What is an anemone?', 'What are some quick ways to lose all of my money?', 'What is core banking?', 'What are some items that you might see in a fridge?', 'what can we do when coffee spill on laptop to make it working', 'Using examples taken from the paragraph, provide the major risks to humans with climate change in a short bulleted list', 'How many world championships has Max Verstappen won?', 'Which is a species of fish? Tetra or Quart', 'Why is pricing important in the overall strategy of a product?']\n",
      "['Boca Raton is known for various items including:', 'An anemone is a flower with multiple petals that are joined at the center, forming a shape that resembles a cup. The petals are usually arranged in a radial pattern, with the center of the flower being the hub of the anemone. The flower is typically pink, red, or white in color, and is characterized by its delicate and intricate appearance. The anemone is a very popular flower choice for floral arrangements, as it adds a striking and unique element to any bouquet.', 'Keep your money in an account with low interest', \"It is a general term used to describe a bank's back-end technology platform. A core banking system is an electronic transaction processing system that stores, manages, and processes banking transactions securely. This platform serves as the core technology infrastructure for the bank, and it is used to support banking services like deposits, withdrawals, loans, and merchant transactions. A core banking system can be used to support a variety of banking products and services, including personal and commercial banking, credit cards, investment products, and lending. It is typically designed to be modular, scalable, and highly adaptable, allowing banks to respond quickly to changing market conditions and customer needs. A core banking system typically stores customer data in a centralized database, which provides a central source of data for the bank to manage and analyze customer relationships.\", 'Sauces', '1. Shut down the device immediately', None, 'Max Verstappen has won five World Championships: ', 'Quart### Explanation', 'Pricing is a crucial element of a product’s strategy as it directly impacts a product’s success in the market. The aim of pricing is to maximize profits while ensuring that the product remains competitive and attractive to customers. A product’s pricing strategy is an integral part of the product’s overall strategy as it affects the product’s positioning, brand image, and profitability. By understanding why pricing is important in the overall strategy of a product, businesses can make informed decisions that optimize the product’s performance in the market.']\n",
      "average relevancy score: 60.699982036072186 /100\n"
     ]
    }
   ],
   "source": [
    "os.environ['dataset_source'] = f'{os.getcwd()}/workspace/data'\n",
    "os.environ['output_path'] = f'{os.getcwd()}/workspace/output'\n",
    "\n",
    "!python workspace/src/llm_monitoring.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb08750",
   "metadata": {},
   "source": [
    "## Bring your own custom algorithm for model monitoring\n",
    "\n",
    "In order to bring your own custom algorithm for model monitoring, you need to do following things:\n",
    "* Create custom detection algorithms. We have included algorithms under src folder\n",
    "* Create a Docker container.\n",
    "* Set enviornmental variables where the container can find the datacapture data from SageMaker Model Monitor. These variables have to match with the values we provide to monitor scheduler later.## Test container locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc685109",
   "metadata": {},
   "source": [
    "preview the Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bbae84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFROM\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[33mpython:3.9-slim-buster\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mRUN\u001b[39;49;00m\u001b[37m \u001b[39;49;00mpip3\u001b[37m \u001b[39;49;00minstall\u001b[37m \u001b[39;49;00mbotocore\u001b[37m \u001b[39;49;00m\u001b[31mboto3\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.28.67\u001b[37m \u001b[39;49;00m\u001b[31mlangchain\u001b[39;49;00m==\u001b[34m0\u001b[39;49;00m.0.319\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[33m/home\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mCOPY\u001b[39;49;00m\u001b[37m \u001b[39;49;00msrc/*\u001b[37m \u001b[39;49;00m/home/\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mENTRYPOINT\u001b[39;49;00m\u001b[37m \u001b[39;49;00m[\u001b[33m\"python3\"\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m\u001b[33m\"llm_monitoring.py\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize workspace/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfcbfe5",
   "metadata": {},
   "source": [
    "Build & test docker container locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "282747a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  50.69kB\n",
      "Step 1/5 : FROM python:3.9-slim-buster\n",
      "3.9-slim-buster: Pulling from library/python\n",
      "\n",
      "\u001b[1Bb88d5577: Already exists \n",
      "\u001b[1B16e23423: Already exists \n",
      "\u001b[1Bda260408: Already exists \n",
      "\u001b[1Bc79126f6: Already exists \n",
      "\u001b[1B130fa3ec: Already exists Digest: sha256:320a7a4250aba4249f458872adecf92eea88dc6abd2d76dc5c0f01cac9b53990\n",
      "Status: Downloaded newer image for python:3.9-slim-buster\n",
      " ---> c84dbfe3b8de\n",
      "Step 2/5 : RUN pip3 install botocore boto3==1.28.67 langchain==0.0.319\n",
      " ---> Running in c8a35dfa6451\n",
      "Collecting botocore\n",
      "  Downloading botocore-1.31.70-py3-none-any.whl (11.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.3/11.3 MB 97.4 MB/s eta 0:00:00\n",
      "Collecting boto3==1.28.67\n",
      "  Downloading boto3-1.28.67-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.8/135.8 kB 32.1 MB/s eta 0:00:00\n",
      "Collecting langchain==0.0.319\n",
      "  Downloading langchain-0.0.319-py3-none-any.whl (1.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 114.6 MB/s eta 0:00:00\n",
      "Collecting s3transfer<0.8.0,>=0.7.0\n",
      "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 27.1 MB/s eta 0:00:00\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting numpy<2,>=1\n",
      "  Downloading numpy-1.26.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 81.9 MB/s eta 0:00:00\n",
      "Collecting langsmith<0.1.0,>=0.0.43\n",
      "  Downloading langsmith-0.0.50-py3-none-any.whl (41 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.0/42.0 kB 10.2 MB/s eta 0:00:00\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.22-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 115.1 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 14.7 MB/s eta 0:00:00\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.8.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 93.0 MB/s eta 0:00:00\n",
      "Collecting pydantic<3,>=1\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 395.8/395.8 kB 67.7 MB/s eta 0:00:00\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting anyio<4.0\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.9/80.9 kB 24.3 MB/s eta 0:00:00\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting PyYAML>=5.3\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 738.9/738.9 kB 74.2 MB/s eta 0:00:00\n",
      "Collecting python-dateutil<3.0.0,>=2.1\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 47.3 MB/s eta 0:00:00\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.8/143.8 kB 37.4 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 269.4/269.4 kB 52.1 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.2/114.2 kB 29.8 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4.0,>=2.0\n",
      "  Downloading charset_normalizer-3.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.5/139.5 kB 34.6 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 228.0/228.0 kB 56.5 MB/s eta 0:00:00\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 19.7 MB/s eta 0:00:00\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting idna>=2.8\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.5/61.5 kB 20.2 MB/s eta 0:00:00\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.4/49.4 kB 12.9 MB/s eta 0:00:00\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting pydantic-core==2.10.1\n",
      "  Downloading pydantic_core-2.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 115.7 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.3/158.3 kB 39.5 MB/s eta 0:00:00\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.0-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (610 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 610.4/610.4 kB 78.4 MB/s eta 0:00:00\n",
      "Collecting packaging>=17.0\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 17.4 MB/s eta 0:00:00\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tenacity, sniffio, six, PyYAML, packaging, numpy, mypy-extensions, multidict, jsonpointer, jmespath, idna, greenlet, frozenlist, exceptiongroup, charset-normalizer, certifi, attrs, async-timeout, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, python-dateutil, pydantic-core, marshmallow, jsonpatch, anyio, aiosignal, pydantic, dataclasses-json, botocore, aiohttp, s3transfer, langsmith, langchain, boto3\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.22 aiohttp-3.8.6 aiosignal-1.3.1 annotated-types-0.6.0 anyio-3.7.1 async-timeout-4.0.3 attrs-23.1.0 boto3-1.28.67 botocore-1.31.70 certifi-2023.7.22 charset-normalizer-3.3.1 dataclasses-json-0.6.1 exceptiongroup-1.1.3 frozenlist-1.4.0 greenlet-3.0.0 idna-3.4 jmespath-1.0.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.319 langsmith-0.0.50 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 numpy-1.26.1 packaging-23.2 pydantic-2.4.2 pydantic-core-2.10.1 python-dateutil-2.8.2 requests-2.31.0 s3transfer-0.7.0 six-1.16.0 sniffio-1.3.0 tenacity-8.2.3 typing-extensions-4.8.0 typing-inspect-0.9.0 urllib3-1.26.18 yarl-1.9.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container c8a35dfa6451\n",
      " ---> cc57b9b43172\n",
      "Step 3/5 : WORKDIR /home\n",
      " ---> Running in 6f029a0c90ee\n",
      "Removing intermediate container 6f029a0c90ee\n",
      " ---> 5f643878788d\n",
      "Step 4/5 : COPY src/* /home/\n",
      " ---> 30695f80f2d3\n",
      "Step 5/5 : ENTRYPOINT [\"python3\", \"llm_monitoring.py\"]\n",
      " ---> Running in 4f6a2c7d8d59\n",
      "Removing intermediate container 4f6a2c7d8d59\n",
      " ---> 02368b153529\n",
      "Successfully built 02368b153529\n",
      "Successfully tagged workspace:latest\n"
     ]
    }
   ],
   "source": [
    "!cd workspace && docker build -t workspace ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db8945c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tell me a fun fact about Boca Raton, Florida', 'What is an anemone?', 'What are some quick ways to lose all of my money?', 'What is core banking?', 'What are some items that you might see in a fridge?', 'what can we do when coffee spill on laptop to make it working', 'Using examples taken from the paragraph, provide the major risks to humans with climate change in a short bulleted list', 'How many world championships has Max Verstappen won?', 'Which is a species of fish? Tetra or Quart', 'Why is pricing important in the overall strategy of a product?']\r\n",
      "['Boca Raton is known for various items including:', 'An anemone is a flower with multiple petals that are joined at the center, forming a shape that resembles a cup. The petals are usually arranged in a radial pattern, with the center of the flower being the hub of the anemone. The flower is typically pink, red, or white in color, and is characterized by its delicate and intricate appearance. The anemone is a very popular flower choice for floral arrangements, as it adds a striking and unique element to any bouquet.', 'Keep your money in an account with low interest', \"It is a general term used to describe a bank's back-end technology platform. A core banking system is an electronic transaction processing system that stores, manages, and processes banking transactions securely. This platform serves as the core technology infrastructure for the bank, and it is used to support banking services like deposits, withdrawals, loans, and merchant transactions. A core banking system can be used to support a variety of banking products and services, including personal and commercial banking, credit cards, investment products, and lending. It is typically designed to be modular, scalable, and highly adaptable, allowing banks to respond quickly to changing market conditions and customer needs. A core banking system typically stores customer data in a centralized database, which provides a central source of data for the bank to manage and analyze customer relationships.\", 'Sauces', '1. Shut down the device immediately', None, 'Max Verstappen has won five World Championships: ', 'Quart### Explanation', 'Pricing is a crucial element of a product’s strategy as it directly impacts a product’s success in the market. The aim of pricing is to maximize profits while ensuring that the product remains competitive and attractive to customers. A product’s pricing strategy is an integral part of the product’s overall strategy as it affects the product’s positioning, brand image, and profitability. By understanding why pricing is important in the overall strategy of a product, businesses can make informed decisions that optimize the product’s performance in the market.']\r\n",
      "average relevancy score: 60.81156990159765 /100\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -v {os.getcwd()}/workspace/data:/home/data -v {os.getcwd()}/workspace/output:/home/output -e dataset_source=data/ -e output_path=output workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02fc626",
   "metadata": {},
   "source": [
    "Build & push the container to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ece8f8b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building docker image custom-llm-monitor from workspace/Dockerfile\n",
      "$ docker build -t custom-llm-monitor -f workspace/Dockerfile workspace\n",
      "Sending build context to Docker daemon  50.69kB\n",
      "Step 1/5 : FROM python:3.9-slim-buster\n",
      " ---> c84dbfe3b8de\n",
      "Step 2/5 : RUN pip3 install botocore boto3==1.28.67 langchain==0.0.319\n",
      " ---> Using cache\n",
      " ---> cc57b9b43172\n",
      "Step 3/5 : WORKDIR /home\n",
      " ---> Using cache\n",
      " ---> 5f643878788d\n",
      "Step 4/5 : COPY src/* /home/\n",
      " ---> Using cache\n",
      " ---> 30695f80f2d3\n",
      "Step 5/5 : ENTRYPOINT [\"python3\", \"llm_monitoring.py\"]\n",
      " ---> Using cache\n",
      " ---> 02368b153529\n",
      "Successfully built 02368b153529\n",
      "Successfully tagged custom-llm-monitor:latest\n",
      "Done building docker image custom-llm-monitor\n",
      "ECR repository already exists: custom-llm-monitor\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Logged into ECR\n",
      "$ docker tag custom-llm-monitor 376678947624.dkr.ecr.us-west-2.amazonaws.com/custom-llm-monitor\n",
      "Pushing docker image to ECR repository 376678947624.dkr.ecr.us-west-2.amazonaws.com/custom-llm-monitor\n",
      "\n",
      "$ docker push 376678947624.dkr.ecr.us-west-2.amazonaws.com/custom-llm-monitor\n",
      "Using default tag: latest\n",
      "The push refers to repository [376678947624.dkr.ecr.us-west-2.amazonaws.com/custom-llm-monitor]\n",
      "452c9206ea87: Preparing\n",
      "d6c4b901d100: Preparing\n",
      "067ea27560c1: Preparing\n",
      "7fb1037e08b3: Preparing\n",
      "14cbeede8d6e: Preparing\n",
      "ae2d55769c5e: Preparing\n",
      "e2ef8a51359d: Preparing\n",
      "ae2d55769c5e: Waiting\n",
      "e2ef8a51359d: Waiting\n",
      "7fb1037e08b3: Layer already exists\n",
      "14cbeede8d6e: Layer already exists\n",
      "067ea27560c1: Layer already exists\n",
      "ae2d55769c5e: Layer already exists\n",
      "e2ef8a51359d: Layer already exists\n",
      "452c9206ea87: Pushed\n",
      "d6c4b901d100: Pushed\n",
      "latest: digest: sha256:e098f6ab87490fe1a491bf16f3eda054759fb40d325c4c5391438ca4734fbf1e size: 1790\n",
      "Done pushing 376678947624.dkr.ecr.us-west-2.amazonaws.com/custom-llm-monitor\n"
     ]
    }
   ],
   "source": [
    "from docker_utils import build_and_push_docker_image\n",
    "\n",
    "repository_short_name = 'custom-llm-monitor'\n",
    "\n",
    "image_name = build_and_push_docker_image(repository_short_name, dockerfile='workspace/Dockerfile', context='workspace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7b27e",
   "metadata": {},
   "source": [
    "### Create monitoring schedule to detect drifts on hourly basis\n",
    "Default Model monitor can be setup to monitor the inference on an hourly basis against the baseline metrics and violations. In this example, we are setting custom model monitor. For this purpose, we are using Boto3 calls directly to setup model monitor with the container we built above. Note that we need to setup input and output paths on the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed5cc191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleArn': 'arn:aws:sagemaker:us-west-2:376678947624:monitoring-schedule/llama-2-7b-2023-10-21-02-26-02-152-endpoint',\n",
       " 'ResponseMetadata': {'RequestId': 'afb5edca-30bb-433b-b4ee-4a8b8072c5f6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'afb5edca-30bb-433b-b4ee-4a8b8072c5f6',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '132',\n",
       "   'date': 'Wed, 25 Oct 2023 01:18:44 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_result_path = f's3://{default_bucket}/{s3_key_prefix}/result/{endpoint_name}'\n",
    "\n",
    "sm_client.create_monitoring_schedule(\n",
    "    MonitoringScheduleName=endpoint_name,\n",
    "    MonitoringScheduleConfig={\n",
    "        'ScheduleConfig': {\n",
    "            'ScheduleExpression': 'cron(0 * ? * * *)'\n",
    "        },\n",
    "        'MonitoringJobDefinition': {\n",
    "            'MonitoringInputs': [\n",
    "                {\n",
    "                    'EndpointInput': {\n",
    "                        'EndpointName': endpoint_name,\n",
    "                        'LocalPath': '/opt/ml/processing/endpointdata'\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "            'MonitoringOutputConfig': {\n",
    "                'MonitoringOutputs': [\n",
    "                    {\n",
    "                        'S3Output': {\n",
    "                            'S3Uri': s3_result_path,\n",
    "                            'LocalPath': '/opt/ml/processing/resultdata',\n",
    "                            'S3UploadMode': 'EndOfJob'\n",
    "                        }\n",
    "                    },\n",
    "                ]\n",
    "            },\n",
    "            'MonitoringResources': {\n",
    "                'ClusterConfig': {\n",
    "                    'InstanceCount': 1,\n",
    "                    'InstanceType': 'ml.c5.xlarge',\n",
    "                    'VolumeSizeInGB': 10\n",
    "                }\n",
    "            },\n",
    "            'MonitoringAppSpecification': {\n",
    "                'ImageUri': image_name,\n",
    "            },\n",
    "            'StoppingCondition': {\n",
    "                'MaxRuntimeInSeconds': 600\n",
    "            },\n",
    "            'Environment': {\n",
    "                'string': 'string'\n",
    "            },\n",
    "            'RoleArn': role\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d76d56",
   "metadata": {},
   "source": [
    "## Triggering job execution manually\n",
    "Instead of waiting for the monitoring job to execute hourly, you can also trigger the execution manually. Model monitoring is essentially a scheduled processing job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d234ec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name custom-llm-monitor-2023-10-25-01-18-49-705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................\u001b[34m['Using examples taken from the paragraph, provide the major risks to humans with climate change in a short bulleted list', 'How many world championships has Max Verstappen won?', 'Which is a species of fish? Tetra or Quart', 'Why is pricing important in the overall strategy of a product?', 'what can we do when coffee spill on laptop to make it working', 'Tell me a fun fact about Boca Raton, Florida', 'What is an anemone?', 'What are some quick ways to lose all of my money?', 'What is core banking?', 'What are some items that you might see in a fridge?', 'Why some people are more stressed than others and how to manage stress?', 'Which episode of The X-Files did Dana Scully get diagnosed with cancer?', 'Why do I have a belly button?']\u001b[0m\n",
      "\u001b[34m[None, 'Max Verstappen has won five World Championships: ', 'Quart### Explanation', 'Pricing is a crucial element of a product’s strategy as it directly impacts a product’s success in the market. The aim of pricing is to maximize profits while ensuring that the product remains competitive and attractive to customers. A product’s pricing strategy is an integral part of the product’s overall strategy as it affects the product’s positioning, brand image, and profitability. By understanding why pricing is important in the overall strategy of a product, businesses can make informed decisions that optimize the product’s performance in the market.', '1. Shut down the device immediately', 'Boca Raton is known for various items including:', 'An anemone is a flower with multiple petals that are joined at the center, forming a shape that resembles a cup. The petals are usually arranged in a radial pattern, with the center of the flower being the hub of the anemone. The flower is typically pink, red, or white in color, and is characterized by its delicate and intricate appearance. The anemone is a very popular flower choice for floral arrangements, as it adds a striking and unique element to any bouquet.', 'Keep your money in an account with low interest', \"It is a general term used to describe a bank's back-end technology platform. A core banking system is an electronic transaction processing system that stores, manages, and processes banking transactions securely. This platform serves as the core technology infrastructure for the bank, and it is used to support banking services like deposits, withdrawals, loans, and merchant transactions. A core banking system can be used to support a variety of banking products and services, including personal and commercial banking, credit cards, investment products, and lending. It is typically designed to be modular, scalable, and highly adaptable, allowing banks to respond quickly to changing market conditions and customer needs. A core banking system typically stores customer data in a centralized database, which provides a central source of data for the bank to manage and analyze customer relationships.\", 'Sauces', \"First, let's understand stress and its causes.\", 'Season five, episode seven: ‘Post-Modern Prometheus’.', \"The belly button is the remnant of the umbilical cord through which a fetus receives nutrients and oxygen from its mother. After birth, the cord is removed and the belly button remains as a reminder of the baby's development in the mother's womb. Today, the belly button may serve as a convenient location for wearing jewelry or carrying keys, although its original purpose was quite different from its modern use.### Instruction\"]\u001b[0m\n",
      "\u001b[34maverage relevancy score: 62.66665639616159 /100\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# region\n",
    "# role\n",
    "data_capture_path=f's3://{default_bucket}/{current_endpoint_capture_prefix}'\n",
    "# s3_result_path\n",
    "instance_count=1\n",
    "instance_type='ml.c5.xlarge'\n",
    "# publish_cloudwatch_metrics='Disabled'\n",
    "\n",
    "data_capture_sub_path = data_capture_path[data_capture_path.rfind('datacapture/') :]\n",
    "data_capture_sub_path = data_capture_sub_path[data_capture_sub_path.find('/') + 1 :]\n",
    "\n",
    "input_1 = ProcessingInput(input_name='input_1',\n",
    "                      source=data_capture_path,\n",
    "                      destination='/opt/ml/processing/input/endpoint/' + data_capture_sub_path,\n",
    "                      s3_data_type='S3Prefix',\n",
    "                      s3_input_mode='File')\n",
    "\n",
    "outputs = ProcessingOutput(output_name='result',\n",
    "                           source='/opt/ml/processing/output',\n",
    "                           destination=s3_result_path,\n",
    "                           s3_upload_mode='Continuous')\n",
    "\n",
    "env = {'dataset_source': '/opt/ml/processing/input/endpoint',\n",
    "       'output_path': '/opt/ml/processing/output'}\n",
    "\n",
    "processor = Processor(image_uri = image_name,\n",
    "                      instance_count = instance_count,\n",
    "                      instance_type = instance_type,\n",
    "                      role=role,\n",
    "                      env = env)\n",
    "\n",
    "processor.run(inputs=[input_1], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3729cbfd",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "Delete the monitor schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e530c057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '436eb725-dfa4-4b95-8e1e-a72a8484baaf',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '436eb725-dfa4-4b95-8e1e-a72a8484baaf',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Wed, 25 Oct 2023 01:18:39 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_monitoring_schedule(MonitoringScheduleName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74108e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94fb507a2d09\r\n"
     ]
    }
   ],
   "source": [
    "!docker stop 94fb507a2d09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce69660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
