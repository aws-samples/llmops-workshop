{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731c3adb",
   "metadata": {},
   "source": [
    "Using this notebook to test different LLM evaluation techniques\n",
    "\n",
    "[ragas framework](https://github.com/explodinggradients/ragas)\n",
    "[llamaindex](https://gpt-index.readthedocs.io/en/v0.6.36/how_to/evaluation/evaluation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e22fe064",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq pysbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0645263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::376678947624:role/vegetation-management-works-SageMakerExecutionRole-OZ2K30BYST0I\n"
     ]
    }
   ],
   "source": [
    "# Handful of configuration\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import pathlib\n",
    "import re\n",
    "import base64\n",
    "from sagemaker import get_execution_role, session\n",
    "import numpy as np\n",
    "\n",
    "import pysbd\n",
    "\n",
    "from langchain.llms import Bedrock\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "\n",
    "region= boto3.Session().region_name\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495435b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r endpoint_name\n",
    "%store -r default_bucket\n",
    "%store -r current_endpoint_capture_prefix\n",
    "%store -r s3_key_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a5a4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync s3://{default_bucket}/{current_endpoint_capture_prefix} data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573cfea3",
   "metadata": {},
   "source": [
    "## Initialize LLM & util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "007a7132",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2\",\n",
    "    model_kwargs={\"max_tokens_to_sample\": 200,\n",
    "                \"temperature\": 0},\n",
    "    client=boto3.client(\"bedrock-runtime\", region_name='us-west-2'),\n",
    ")\n",
    "\n",
    "\n",
    "embeddings= BedrockEmbeddings(\n",
    "    client=boto3.client(\"bedrock-runtime\", region_name='us-west-2'),\n",
    ")\n",
    "\n",
    "seg = pysbd.Segmenter(language=\"en\", clean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6f69ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base64_to_string(base64_string):\n",
    "    base64_bytes = base64_string.encode('ascii')\n",
    "    string_bytes = base64.b64decode(base64_bytes) \n",
    "    return string_bytes.decode('utf-8')\n",
    "\n",
    "def extract_instructions(text):\n",
    "    pattern = r\"### Instruction\\n(.*?)\\n\\n\"\n",
    "    match = re.search(pattern, text)\n",
    "    return match.group(1)\n",
    "\n",
    "def extract_answers(text):\n",
    "    pattern = r\"### Answer\\n\\n(.*)|### Answer\\n(.*)\"\n",
    "    match = re.search(pattern, text)\n",
    "\n",
    "    return match.group(1) or match.group(2)   \n",
    "\n",
    "def extract_contexts(text):\n",
    "    pattern = r\"### Context\\n(.*?)\\n\\n### Answer\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match is None:\n",
    "        return \"\"\n",
    "    return match.group(1)\n",
    "\n",
    "# Helper function to extract question and answer from dataset\n",
    "def extract_qac(input_data, output_data):\n",
    "    question = extract_instructions(json.loads(input_data)[\"text\"])\n",
    "\n",
    "    context = extract_contexts(json.loads(input_data)[\"text\"])\n",
    "    \n",
    "    generated_text = json.loads(base64_to_string(output_data))[\"outputs\"][0][\"generated_text\"]\n",
    "    answer = extract_answers(generated_text)\n",
    "    return question, answer, context\n",
    "\n",
    "def sent_tokenize(text):\n",
    "    \"\"\"\n",
    "    tokenizer text into sentences\n",
    "    \"\"\"\n",
    "    sentences = seg.segment(text)\n",
    "    assert isinstance(sentences, list)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0ce72",
   "metadata": {},
   "source": [
    "## Answer Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "81d837d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEVANCE_TEMPLATE = \"\"\"\\n\\nHuman: Generate question for the given answer.\\n\\nAssistant:Okay, give me an answer, and I will generate a question.\n",
    "\\nHuman:Answer:\\nThe PSLV-C56 mission is scheduled to be launched on Sunday, 30 July 2023 at 06:30 IST / 01:00 UTC. It will be launched from the Satish Dhawan Space Centre, Sriharikota, Andhra Pradesh, India \n",
    "\\nAssistant:Question:\\nWhen is the scheduled launch date and time for the PSLV-C56 mission, and where will it be launched from?\n",
    "\\nHuman:Answer:\\n{answer}\n",
    "\\nAssistant:Question:\\n\n",
    "\"\"\" \n",
    "\n",
    "EVALUATOR = PromptTemplate(template=RELEVANCE_TEMPLATE, input_variables=[\"answer\"])\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=EVALUATOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff36caa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Why some people are more stressed than others and how to manage stress?', 'Which episode of The X-Files did Dana Scully get diagnosed with cancer?', 'Why do I have a belly button?', 'Tell me a fun fact about Boca Raton, Florida', 'What is an anemone?', 'What are some quick ways to lose all of my money?', 'What is core banking?', 'What are some items that you might see in a fridge?', 'what can we do when coffee spill on laptop to make it working', 'Using examples taken from the paragraph, provide the major risks to humans with climate change in a short bulleted list', 'How many world championships has Max Verstappen won?', 'Which is a species of fish? Tetra or Quart', 'Why is pricing important in the overall strategy of a product?']\n",
      "['', '', '', '', '', '', '', '', '', 'The effects of climate change are impacting humans everywhere in the world. Impacts can now be observed on all continents and ocean regions, with low-latitude, less developed areas facing the greatest risk. Continued warming has potentially “severe, pervasive and irreversible impacts” for people and ecosystems. The risks are unevenly distributed, but are generally greater for disadvantaged people in developing and developed countries.\\n\\nThe WHO has classified climate change as the greatest threat to global health in the 21st century. Extreme weather leads to injury and loss of life, and crop failures to undernutrition. Various infectious diseases are more easily transmitted in a warmer climate, such as dengue fever and malaria. Young children are the most vulnerable to food shortages. Both children and older people are vulnerable to extreme heat. The World Health Organization (WHO) has estimated that between 2030 and 2050, climate change would cause around 250,000 additional deaths per year. They assessed deaths from heat exposure in elderly people, increases in diarrhea, malaria, dengue, coastal flooding, and childhood undernutrition. Over 500,000 more adult deaths are projected yearly by 2050 due to reductions in food availability and quality. By 2100, 50% to 75% of the global population may face climate conditions that are life-threatening due to combined effects of extreme heat and humidity.\\n\\nClimate change is affecting food security. It has caused reduction in global yields of maize, wheat, and soybeans between 1981 and 2010. Future warming could further reduce global yields of major crops. Crop production will probably be negatively affected in low-latitude countries, while effects at northern latitudes may be positive or negative. Up to an additional 183 million people worldwide, particularly those with lower incomes, are at risk of hunger as a consequence of these impacts. Climate change also impacts fish populations. Globally, less will be available to be fished. Regions dependent on glacier water, regions that are already dry, and small islands have a higher risk of water stress due to climate change.\\n\\nEconomic damages due to climate change may be severe and there is a chance of disastrous consequences. Climate change has likely already increased global economic inequality, and this trend is projected to continue. Most of the severe impacts are expected in sub-Saharan Africa, where most of the local inhabitants are dependent upon natural and agricultural resources and South-East Asia. The World Bank estimates that climate change could drive over 120 million people into poverty by 2030.\\n\\nCurrent inequalities based on wealth and social status have worsened due to climate change. Major difficulties in mitigating, adapting, and recovering to climate shocks are faced by marginalized people who have less control over resources. Indigenous people, who are subsistent on their land and ecosystems, will face endangerment to their wellness and lifestyles due to climate change. An expert elicitation concluded that the role of climate change in armed conflict has been small compared to factors such as socio-economic inequality and state capabilities.\\n\\nLow-lying islands and coastal communities are threatened by sea level rise, which makes flooding more common. Sometimes, land is permanently lost to the sea. This could lead to statelessness for people in island nations, such as the Maldives and Tuvalu. In some regions, the rise in temperature and humidity may be too severe for humans to adapt to. With worst-case climate change, models project that almost one-third of humanity might live in extremely hot and uninhabitable climates, similar to the current climate found in the Sahara. These factors can drive environmental migration, both within and between countries. More people are expected to be displaced because of sea level rise, extreme weather and conflict from increased competition over natural resources. Climate change may also increase vulnerability, leading to \"trapped populations\" who are not able to move due to a lack of resources.', \"After winning the 2021 Abu Dhabi Grand Prix, Verstappen became the first Dutch driver to win the Formula One World Championship, and the 34th Formula One World Drivers' Champion. He won his second consecutive Formula One championship the next season.\", '', '']\n",
      "[\"First, let's understand stress and its causes.\", 'Season five, episode seven: ‘Post-Modern Prometheus’.', \"The belly button is the remnant of the umbilical cord through which a fetus receives nutrients and oxygen from its mother. After birth, the cord is removed and the belly button remains as a reminder of the baby's development in the mother's womb. Today, the belly button may serve as a convenient location for wearing jewelry or carrying keys, although its original purpose was quite different from its modern use.### Instruction\", 'Boca Raton is known for various items including:', 'An anemone is a flower with multiple petals that are joined at the center, forming a shape that resembles a cup. The petals are usually arranged in a radial pattern, with the center of the flower being the hub of the anemone. The flower is typically pink, red, or white in color, and is characterized by its delicate and intricate appearance. The anemone is a very popular flower choice for floral arrangements, as it adds a striking and unique element to any bouquet.', 'Keep your money in an account with low interest', \"It is a general term used to describe a bank's back-end technology platform. A core banking system is an electronic transaction processing system that stores, manages, and processes banking transactions securely. This platform serves as the core technology infrastructure for the bank, and it is used to support banking services like deposits, withdrawals, loans, and merchant transactions. A core banking system can be used to support a variety of banking products and services, including personal and commercial banking, credit cards, investment products, and lending. It is typically designed to be modular, scalable, and highly adaptable, allowing banks to respond quickly to changing market conditions and customer needs. A core banking system typically stores customer data in a centralized database, which provides a central source of data for the bank to manage and analyze customer relationships.\", 'Sauces', '1. Shut down the device immediately', None, 'Max Verstappen has won five World Championships: ', 'Quart### Explanation', 'Pricing is a crucial element of a product’s strategy as it directly impacts a product’s success in the market. The aim of pricing is to maximize profits while ensuring that the product remains competitive and attractive to customers. A product’s pricing strategy is an integral part of the product’s overall strategy as it affects the product’s positioning, brand image, and profitability. By understanding why pricing is important in the overall strategy of a product, businesses can make informed decisions that optimize the product’s performance in the market.']\n"
     ]
    }
   ],
   "source": [
    "infer_dir = \"data\"\n",
    "questions, answers, contexts = [], [], []\n",
    "\n",
    "for filepath in pathlib.Path(infer_dir).rglob('*.jsonl'):\n",
    "\n",
    "    with open(filepath.absolute(), 'r') as f:\n",
    "        for line in f:\n",
    "            jsonl = json.loads(line)\n",
    "            input_data = jsonl['captureData']['endpointInput']['data']\n",
    "            output_data = jsonl['captureData']['endpointOutput']['data']\n",
    "            \n",
    "            q, a, c = extract_qac(input_data, output_data)\n",
    "            questions.append(q)\n",
    "            answers.append(a)\n",
    "            contexts.append(c)\n",
    "\n",
    "print(questions)\n",
    "print(contexts)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f5945c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(question, generated_questions, embeddings):\n",
    "    \n",
    "    question_vec = np.asarray(embeddings.embed_query(question)).reshape(1, -1)\n",
    "    gen_question_vec = np.asarray(\n",
    "        embeddings.embed_documents(generated_questions)\n",
    "    )\n",
    "    norm = np.linalg.norm(gen_question_vec, axis=1) * np.linalg.norm(\n",
    "        question_vec, axis=1\n",
    "    )\n",
    "    return (\n",
    "        np.dot(gen_question_vec, question_vec.T).reshape(\n",
    "            -1,\n",
    "        )\n",
    "        / norm\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1cb6865b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6817769524176543,\n",
       " 0.680935428500238,\n",
       " 0.7104259099043895,\n",
       " 0.8254220458663453,\n",
       " 0.891557822769294,\n",
       " 0.5674255587239212,\n",
       " 0.9181388091377596,\n",
       " 0.27697335771643194,\n",
       " 0.291954410981584,\n",
       " 0.03925079183807778,\n",
       " 0.9761480549581559,\n",
       " 0.3190104003843797,\n",
       " 0.9384713210148533]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for q, a in zip(questions, answers):\n",
    "    results = []\n",
    "    for i in range(5):\n",
    "        results.append(llm_chain.run(answer=a).strip())\n",
    "    cosine_sim = calculate_similarity(q, results, embeddings)\n",
    "    scores.append(cosine_sim.mean())\n",
    "    \n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e91c8650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6244223741702372"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827313d6",
   "metadata": {},
   "source": [
    "## Faithfulness\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734db00d",
   "metadata": {},
   "source": [
    "## Context Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1df252bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_PRECISION_TEMPLATE = \"\"\"\\n\\nHuman: Please extract relevant sentences from the provided context that is absolutely required answer the following question. If no relevant sentences are found, or if you believe the question cannot be answered from the given context, return the phrase \"Insufficient Information\".  While extracting candidate sentences you're not allowed to make any changes to sentences from given context.\n",
    "\\nquestion:{question}\n",
    "\\ncontext:\\n{context}\n",
    "\\nAssistant: candidate sentences:\n",
    "\"\"\" \n",
    "\n",
    "EVALUATOR = PromptTemplate(template=CONTEXT_PRECISION_TEMPLATE, input_variables=[\"question\", \"context\"])\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=EVALUATOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ccedfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap(context_sent, generated_context):\n",
    "    overlap_scores = []\n",
    "    for gc in generated_context:\n",
    "        indices = (\n",
    "            sent_tokenize(gc)\n",
    "            if gc.lower() != \"insufficient information.\"\n",
    "            else []\n",
    "        )\n",
    "\n",
    "        if len(context_sent) == 0:\n",
    "            score = 0\n",
    "        else:\n",
    "            score = min(len(indices) / len(context_sent), 1)\n",
    "        \n",
    "        overlap_scores.append(score)\n",
    "            \n",
    "    return np.mean(overlap_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6b818b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2972972972972973, 1.0]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for q, c in zip(questions, contexts):\n",
    "    if c != \"\":\n",
    "        context_sent = sent_tokenize(c)\n",
    "        \n",
    "        results = []\n",
    "        for i in range(5):\n",
    "            results.append(llm_chain.run(question=q, context=c).strip())\n",
    "\n",
    "        score = calculate_overlap(context_sent, results)\n",
    "        \n",
    "        scores.append(score)\n",
    "        \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "86ff49ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6486486486486487"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3af39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
